{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saikoushiknalubola/anndata_annam/blob/main/Challenge-1./notebooks/training.ipnyb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "miXCr5sM-q4U"
      },
      "outputs": [],
      "source": [
        "# training.ipynb\n",
        "\n",
        "\"\"\"\n",
        "Author: Annam.ai IIT Ropar\n",
        "Team Name: anndata\n",
        "Team Members: N. Saikoushik, M. Sai Teja, G. Navya Sri, N. Chandhana Priya, V. Asmitha\n",
        "Leaderboard Rank: 22\n",
        "\"\"\"\n",
        "\n",
        "# This is the notebook used for training the model.\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import torch\n",
        "from torchvision import models, transforms\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Paths\n",
        "data_dir = '/kaggle/input/soil-classification/soil_classification-2025'\n",
        "train_csv = os.path.join(data_dir, 'train.csv')\n",
        "train_images = os.path.join(data_dir, 'train')\n",
        "\n",
        "# Load data\n",
        "train_df = pd.read_csv(train_csv)\n",
        "label_encoder = LabelEncoder()\n",
        "train_df['label_encoded'] = label_encoder.fit_transform(train_df['label'])\n",
        "\n",
        "# Define image transformations\n",
        "image_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load pretrained ResNet18\n",
        "model_cnn = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n",
        "model_cnn.fc = torch.nn.Identity()\n",
        "model_cnn = model_cnn.to(device)\n",
        "model_cnn.eval()\n",
        "\n",
        "# Extract features\n",
        "def extract_features(df):\n",
        "    features = []\n",
        "    with torch.no_grad():\n",
        "        for _, row in tqdm(df.iterrows(), total=len(df)):\n",
        "            img_path = os.path.join(train_images, row['image'])\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            img_tensor = image_transforms(img).unsqueeze(0).to(device)\n",
        "            feat = model_cnn(img_tensor).squeeze(0).cpu().numpy()\n",
        "            features.append(feat)\n",
        "    return np.array(features)\n",
        "\n",
        "X = extract_features(train_df)\n",
        "y = train_df['label_encoded'].values\n",
        "\n",
        "# Train Random Forest with cross-validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "f1_scores = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    clf.fit(X[train_idx], y[train_idx])\n",
        "    val_preds = clf.predict(X[val_idx])\n",
        "    f1 = f1_score(y[val_idx], val_preds, average='weighted')\n",
        "    print(f'Fold {fold+1} F1 Score: {f1:.4f}')\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "print(f'Average F1 Score: {np.mean(f1_scores):.4f}')\n",
        "\n",
        "# Save the final model\n",
        "import joblib\n",
        "joblib.dump(clf, 'final_random_forest_model.pkl')\n"
      ]
    }
  ]
}