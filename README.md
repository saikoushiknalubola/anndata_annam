<h1> 🏆 Soil Classification Challenge Submission </h1> <p> This project was developed as part of the Hackathon + Internship opportunity organized by IIT Ropar and Annam.ai. Our team focused on developing top-performing, well-documented machine learning models to classify soil types and contribute to AI-driven sustainable agriculture. </p> <h2> 👥 Team Details </h2> <ul> <li><strong>Team Name:</strong> anndata</li> <li><strong>Team Members:</strong></li> <ul> <li>N. Saikoushik</li> <li>M. Sai Teja</li> <li>G. Navya Sri</li> <li>N. Chandhana Priya</li> <li>V. Asmitha</li> </ul> <li><strong>Leaderboard Rank:</strong> 22 (Part 1)</li> <li><strong>Kaggle Score:</strong> 1.000</li> </ul> <h2> 🗂️ Project Structure </h2> <pre><code>. ├── notebooks/ │ ├── training.ipynb # Model training notebook │ └── inference.ipynb # Inference + submission notebook ├── requirements.txt # Python dependencies ├── download.sh # Script to download Kaggle dataset ├── submission.csv # Final output predictions └── README.md # This file </code></pre> <h2> 🧠 Approach Overview </h2> <ul> <li><strong>Task:</strong> Classify soil images into four categories (Alluvial, Black, Clay, Red) or binary (Soil / Not-Soil).</li> <li><strong>Modeling:</strong> We combined deep learning feature extraction with classical machine learning classifiers for optimal performance.</li> <li><strong>Key Techniques:</strong></li> <ul> <li>Transfer learning with pretrained ResNet architectures</li> <li>Random Forest classifiers on extracted deep features</li> <li>Stratified K-Fold Cross-Validation</li> <li>Test-Time Augmentation (TTA) for robust predictions</li> </ul> </ul> <h2> 💡 Code & Documentation </h2> <h3> 📓 training.ipynb </h3> <ul> <li>Loads and preprocesses soil image data</li> <li>Extracts 512-D feature vectors using pretrained ResNet-18 (ImageNet)</li> <li>Trains Random Forest classifiers using cross-validation</li> <li>Logs performance metrics, plots confusion matrices, and saves best models</li> </ul> <h3> 📓 inference.ipynb </h3> <ul> <li>Loads trained models and feature extractors</li> <li>Applies Test-Time Augmentation (horizontal/vertical flips, crops) for stable predictions</li> <li>Generates and saves submission-ready CSV files following Kaggle format</li> </ul> <h3> 📊 Performance Summary </h3> <table> <tr><th>Fold</th><th>Macro F1 Score</th></tr> <tr><td>1</td><td>0.94</td></tr> <tr><td>2</td><td>0.94</td></tr> <tr><td>3</td><td>0.95</td></tr> <tr><td>4</td><td>0.95</td></tr> <tr><td>5</td><td>0.99</td></tr> <tr><td><strong>Average</strong></td><td><strong>0.955</strong></td></tr> </table> <div> ✅ <strong>Public Leaderboard Score:</strong> 1.000 </div> <h2> ⚙ Setup Instructions </h2> <ol> <li>Clone the repository: <pre><code>git clone https://github.com/saikoushiknalubola/anndata_annam cd anndata_annam</code></pre> </li> <li>Install the required packages: <pre><code>pip install -r requirements.txt</code></pre> </li> <li>Download the dataset: <pre><code>bash download.sh</code></pre> </li> <li>Run training and inference: <ul> <li><code>notebooks/training.ipynb</code>: trains models</li> <li><code>notebooks/inference.ipynb</code>: generates predictions and submission CSV</li> </ul> </li> </ol> <h2> ⚡ Why Our Approach Works </h2> <ul> <li>✅ Combines the power of deep feature representations and classical machine learning.</li> <li>✅ Uses robust cross-validation to avoid overfitting and ensure stability.</li> <li>✅ Applies TTA at inference to squeeze out maximum accuracy.</li> <li>✅ Code is carefully structured, well-commented, and reproducible for academic review.</li> </ul> <h2> 🤝 Acknowledgements </h2> <ul> <li>Competition organizers (Annam.ai, IIT Ropar) for providing the dataset and challenge setup</li> <li>PyTorch Model Zoo for pretrained ResNet models</li> </ul> <h2> 👨‍💻 Author </h2> <p> <strong>Team anndata</strong><br/> Lead Contact: N. Saikoushik </p> <h2> 📬 Contact </h2> <ul> <li>Email: <code>saikoushiknalubola@gmail.com</code></li> </ul> <h2> ⚖️ License </h2> <p>This project is licensed under the MIT License.</p>
